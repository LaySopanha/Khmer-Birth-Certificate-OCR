{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19e43f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from paddleocr import PaddleOCR, LayoutDetection\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0e3e884",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '../Birth_Certificate/birth_certificate2.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66ff7550",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUsing official model (PP-DocLayout_plus-L), the model files will be automatically downloaded and saved in C:\\Users\\User\\.paddlex\\official_models.\u001b[0m\n",
      "\u001b[32m{'res': {'input_path': './image/birth_certificate2.jpg', 'page_index': None, 'boxes': [{'cls_id': 8, 'label': 'table', 'score': 0.976961076259613, 'coordinate': [65.155815, 315.28937, 765.1158, 1025.2493]}, {'cls_id': 2, 'label': 'text', 'score': 0.8516296148300171, 'coordinate': [57.749012, 188.04932, 233.96507, 278.10498]}, {'cls_id': 2, 'label': 'text', 'score': 0.8266314268112183, 'coordinate': [527.2945, 186.37842, 779.3873, 263.49997]}, {'cls_id': 2, 'label': 'text', 'score': 0.7633093595504761, 'coordinate': [542.255, 94.999146, 739.07404, 172.63039]}, {'cls_id': 6, 'label': 'figure_title', 'score': 0.7157213687896729, 'coordinate': [338.3753, 267.06952, 487.36392, 307.1265]}, {'cls_id': 15, 'label': 'seal', 'score': 0.6964489221572876, 'coordinate': [462.2952, 1074.6266, 695.2114, 1217.5571]}, {'cls_id': 2, 'label': 'text', 'score': 0.5042234659194946, 'coordinate': [402.7411, 1041.7764, 764.4622, 1078.9114]}]}}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = LayoutDetection(model_name=\"PP-DocLayout_plus-L\")\n",
    "output = model.predict(image_path, batch_size=1, layout_nms=True)\n",
    "for res in output:\n",
    "    res.print()\n",
    "    res.save_to_img(save_path=\"./output/\")\n",
    "    res.save_to_json(save_path=\"./output/res.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13120ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUsing official model (RT-DETR-L_wired_table_cell_det), the model files will be automatically downloaded and saved in C:\\Users\\User\\.paddlex\\official_models.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m{'res': {'input_path': './image/birth_certificate2.jpg', 'page_index': None, 'boxes': [{'cls_id': 0, 'label': 'cell', 'score': 0.966800332069397, 'coordinate': [67.33393, 879.287, 324.54202, 969.9971]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9651891589164734, 'coordinate': [66.27282, 584.08765, 324.78174, 663.3129]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9641120433807373, 'coordinate': [324.0983, 879.8517, 542.519, 972.5461]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9630168080329895, 'coordinate': [324.46347, 584.0238, 763.27563, 663.83826]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9604591727256775, 'coordinate': [64.32641, 408.01602, 180.91158, 496.38187]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9579028487205505, 'coordinate': [322.06055, 316.0503, 684.3066, 363.57434]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9567340612411499, 'coordinate': [322.47156, 362.46793, 684.2508, 408.12595]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9560217261314392, 'coordinate': [62.723473, 317.40585, 322.4925, 364.2276]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9558728933334351, 'coordinate': [63.597443, 363.87527, 322.79587, 408.45245]}, {'cls_id': 0, 'label': 'cell', 'score': 0.955580472946167, 'coordinate': [323.91315, 495.656, 763.95166, 540.6453]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9552772045135498, 'coordinate': [323.49765, 450.7108, 764.2777, 497.28366]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9550239443778992, 'coordinate': [541.9108, 881.38275, 762.5897, 975.23926]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9549717307090759, 'coordinate': [67.83038, 969.7771, 324.41916, 1022.0741]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9542612433433533, 'coordinate': [324.20853, 539.7106, 763.69305, 584.5714]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9540027379989624, 'coordinate': [66.9317, 792.0995, 324.7924, 836.22144]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9537026286125183, 'coordinate': [67.19588, 835.8076, 324.49658, 879.8071]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9531382322311401, 'coordinate': [322.88147, 406.30093, 764.4556, 452.58136]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9516064524650574, 'coordinate': [683.8829, 315.5633, 764.77606, 406.4121]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9510296583175659, 'coordinate': [66.38803, 663.05756, 325.1098, 706.52313]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9493709206581116, 'coordinate': [180.63858, 452.51126, 323.811, 497.25467]}, {'cls_id': 0, 'label': 'cell', 'score': 0.949172854423523, 'coordinate': [65.27384, 496.83093, 324.26886, 540.9173]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9489837288856506, 'coordinate': [65.94188, 540.2163, 324.66037, 584.6019]}, {'cls_id': 0, 'label': 'cell', 'score': 0.948940634727478, 'coordinate': [66.605934, 706.09155, 325.0277, 750.0364]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9484401345252991, 'coordinate': [180.35573, 408.16296, 323.31006, 452.70923]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9462144374847412, 'coordinate': [324.72998, 663.6154, 542.0228, 706.7108]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9460386633872986, 'coordinate': [323.92242, 970.7098, 763.1668, 1027.3354]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9459617137908936, 'coordinate': [541.5903, 664.058, 762.7373, 707.1322]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9452131986618042, 'coordinate': [324.78, 706.2568, 542.0136, 750.44305]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9451386332511902, 'coordinate': [66.81249, 749.5746, 324.90738, 792.5995]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9448781609535217, 'coordinate': [324.36835, 836.40686, 542.2095, 880.997]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9436643719673157, 'coordinate': [324.6469, 792.50757, 542.1824, 837.4575]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9424511194229126, 'coordinate': [541.90497, 838.02686, 762.39746, 882.729]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9393700361251831, 'coordinate': [541.65204, 706.62024, 762.5725, 751.3836]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9380224943161011, 'coordinate': [324.83514, 749.6408, 541.97156, 793.75916]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9373664855957031, 'coordinate': [541.7294, 794.34827, 762.28687, 839.2335]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9346176385879517, 'coordinate': [541.6755, 750.6603, 762.5212, 795.4314]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9000148773193359, 'coordinate': [0, 1023.8297, 828.29517, 1280]}, {'cls_id': 0, 'label': 'cell', 'score': 0.8151311874389648, 'coordinate': [0.2838648, 0.29542923, 831, 316.42328]}]}}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from paddleocr import TableCellsDetection\n",
    "model = TableCellsDetection(model_name=\"RT-DETR-L_wired_table_cell_det\")\n",
    "output = model.predict(image_path, threshold=0.3, batch_size=1)\n",
    "for res in output:\n",
    "    res.print(json_format=False)\n",
    "    res.save_to_img(\"./output/\")\n",
    "    res.save_to_json(\"./output/res.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0573334f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCreating model: ('PP-OCRv5_server_det', None)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUsing official model (PP-OCRv5_server_det), the model files will be automatically downloaded and saved in C:\\Users\\User\\.paddlex\\official_models.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-OCRv5_server_rec', None)\u001b[0m\n",
      "\u001b[32mUsing official model (PP-OCRv5_server_rec), the model files will be automatically downloaded and saved in C:\\Users\\User\\.paddlex\\official_models.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-OCRv5_mobile_det', None)\u001b[0m\n",
      "\u001b[32mUsing official model (PP-OCRv5_mobile_det), the model files will be automatically downloaded and saved in C:\\Users\\User\\.paddlex\\official_models.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to https://paddle-model-ecology.bj.bcebos.com/paddlex/official_inference_model/paddle3.0.0/PP-OCRv5_mobile_det_infer.tar ...\n",
      "Downloading PP-OCRv5_mobile_det_infer.tar ...\n",
      "[==================================================] 100.00%\n",
      "Extracting PP-OCRv5_mobile_det_infer.tar\n",
      "[==================================================] 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCreating model: ('PP-OCRv5_server_rec', None)\u001b[0m\n",
      "\u001b[32mUsing official model (PP-OCRv5_server_rec), the model files will be automatically downloaded and saved in C:\\Users\\User\\.paddlex\\official_models.\u001b[0m\n",
      "\u001b[32m{'res': {'input_path': '../Birth_Certificate/birth_certificate2.jpg', 'page_index': None, 'model_settings': {'use_doc_preprocessor': True, 'use_textline_orientation': False}, 'doc_preprocessor_res': {'input_path': None, 'page_index': None, 'model_settings': {'use_doc_orientation_classify': False, 'use_doc_unwarping': False}, 'angle': -1}, 'dt_polys': array([[[ 545,   94],\n",
      "        ...,\n",
      "        [ 545,  129]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 512, 1194],\n",
      "        ...,\n",
      "        [ 511, 1204]]], dtype=int16), 'text_det_params': {'limit_side_len': 64, 'limit_type': 'min', 'thresh': 0.3, 'max_side_limit': 4000, 'box_thresh': 0.6, 'unclip_ratio': 1.5}, 'text_type': 'general', 'textline_orientation_angles': array([-1, ..., -1]), 'text_rec_score_thresh': 0.0, 'rec_texts': ['5', '', '*', '3', '8nO.', '8', '6/200', '8', 'se', '5', 'cs', '2', 'ing', '227', '5', '', '', 'jgnit', '399', 'e', 'Rurmi', '8', 'ig ie ginnn', '', 'gnigunnn', '', '   ε   ', '', '享', 'a', 'ann n', '8n', 'w', '', '', 'D', '', 'pgid', 'nurm', '85', '895', 'i is gnn', '', '', 'gnigunnn', '2', 'n      ', '2', '0', '0', '2', '5', '0', '5', 'ggigininn', ' ', ' ', 'tse.', '', '28630', '55ES5-6525', 'n'], 'rec_scores': array([0.4172779 , ..., 0.21765393]), 'rec_polys': array([[[ 545,   94],\n",
      "        ...,\n",
      "        [ 545,  129]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 512, 1194],\n",
      "        ...,\n",
      "        [ 511, 1204]]], dtype=int16), 'rec_boxes': array([[ 545, ...,  129],\n",
      "       ...,\n",
      "       [ 511, ..., 1206]], dtype=int16)}}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from paddleocr import PaddleOCR  \n",
    "\n",
    "ocr = PaddleOCR(\n",
    "    use_doc_orientation_classify=False, # Disables document orientation classification model via this parameter\n",
    "    use_doc_unwarping=False, # Disables text image rectification model via this parameter\n",
    "    use_textline_orientation=False, # Disables text line orientation classification model via this parameter\n",
    ")\n",
    "# ocr = PaddleOCR(lang=\"en\") # Uses English model by specifying language parameter\n",
    "# ocr = PaddleOCR(ocr_version=\"PP-OCRv4\") # Uses other PP-OCR versions via version parameter\n",
    "# ocr = PaddleOCR(device=\"gpu\") # Enables GPU acceleration for model inference via device parameter\n",
    "ocr = PaddleOCR(\n",
    "    text_detection_model_name=\"PP-OCRv5_mobile_det\",\n",
    "    # text_recognition_model_name=\"PP-OCRv5_mobile_rec\",\n",
    "    use_doc_orientation_classify=False,\n",
    "    use_doc_unwarping=False,\n",
    "    use_textline_orientation=False,\n",
    ") # Switch to PP-OCRv5_mobile models\n",
    "result = ocr.predict(image_path)  \n",
    "for res in result:  \n",
    "    res.print()  \n",
    "    res.save_to_img(\"output\")  \n",
    "    res.save_to_json(\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93b8e614",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_8928\\1638214140.py:16: DeprecationWarning: The parameter `use_angle_cls` has been deprecated and will be removed in the future. Please use `use_textline_orientation` instead.\n",
      "  ocr_detector = PaddleOCR(use_angle_cls=False, lang='en')\n",
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)\u001b[0m\n",
      "\u001b[32mUsing official model (PP-LCNet_x1_0_doc_ori), the model files will be automatically downloaded and saved in C:\\Users\\User\\.paddlex\\official_models.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing PaddleOCR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCreating model: ('UVDoc', None)\u001b[0m\n",
      "\u001b[32mUsing official model (UVDoc), the model files will be automatically downloaded and saved in C:\\Users\\User\\.paddlex\\official_models.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-OCRv5_server_det', None)\u001b[0m\n",
      "\u001b[32mUsing official model (PP-OCRv5_server_det), the model files will be automatically downloaded and saved in C:\\Users\\User\\.paddlex\\official_models.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-OCRv5_server_rec', None)\u001b[0m\n",
      "\u001b[32mUsing official model (PP-OCRv5_server_rec), the model files will be automatically downloaded and saved in C:\\Users\\User\\.paddlex\\official_models.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PaddleOCR initialized.\n",
      "Running text detection with PaddleOCR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_8928\\1638214140.py:27: DeprecationWarning: Please use `predict` instead.\n",
      "  paddle_results = ocr_detector.ocr(image)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Khmer recognition with Tesseract (with correct formatting) ---\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'i'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m box \u001b[38;5;241m=\u001b[39m line[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# The original bounding box from PaddleOCR\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Crop the image using a rectangular bounding box\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m x_min \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m x_max \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mmax\u001b[39m([p[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m box]))\n\u001b[0;32m     41\u001b[0m y_min \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mmin\u001b[39m([p[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m box]))\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'i'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from paddleocr import PaddleOCR\n",
    "from pytesseract import Output # We need this to specify the output format\n",
    "import numpy as np # Useful for drawing boxes later\n",
    "\n",
    "# --- Configuration (WINDOWS USERS: uncomment and set this path) ---\n",
    "# Make sure Tesseract is installed and its path is correct\n",
    "try:\n",
    "    pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "except Exception:\n",
    "    print(\"Pytesseract config skipped (not on Windows or Tesseract is in PATH).\")\n",
    "\n",
    "# --- Step 1: Initialize PaddleOCR for DETECTION ---\n",
    "print(\"Initializing PaddleOCR...\")\n",
    "ocr_detector = PaddleOCR(use_angle_cls=False, lang='en')\n",
    "print(\"PaddleOCR initialized.\")\n",
    "\n",
    "# --- Step 2: Load the image ---\n",
    "image = cv2.imread(image_path)\n",
    "if image is None:\n",
    "    raise FileNotFoundError(f\"Image not found at {image_path}\")\n",
    "\n",
    "# --- Step 3: Run detection with PaddleOCR ---\n",
    "print(\"Running text detection with PaddleOCR...\")\n",
    "# IMPORTANT: Use .ocr() not .predict(). .ocr() gives the structure we want to mimic.\n",
    "paddle_results = ocr_detector.ocr(image)\n",
    "\n",
    "# This list will hold all our reformatted lines\n",
    "reformatted_lines = []\n",
    "\n",
    "print(\"\\n--- Running Khmer recognition with Tesseract (with correct formatting) ---\")\n",
    "# --- Step 4: Iterate through boxes, crop, and run Tesseract ---\n",
    "if paddle_results and paddle_results[0]:\n",
    "    for line in paddle_results[0]:\n",
    "        box = line[0]  # The original bounding box from PaddleOCR\n",
    "        \n",
    "        # Crop the image using a rectangular bounding box\n",
    "        x_min = int(min([p[0] for p in box]))\n",
    "        x_max = int(max([p[0] for p in box]))\n",
    "        y_min = int(min([p[1] for p in box]))\n",
    "        y_max = int(max([p[1] for p in box]))\n",
    "        \n",
    "        cropped_image = image[y_min:y_max, x_min:x_max]\n",
    "        \n",
    "        if cropped_image.size == 0:\n",
    "            continue\n",
    "\n",
    "        # --- Step 5: Recognize with Tesseract using image_to_data ---\n",
    "        try:\n",
    "            # Get detailed data for each word, including confidence\n",
    "            tesseract_data = pytesseract.image_to_data(\n",
    "                cropped_image,\n",
    "                lang='khm',\n",
    "                config='--psm 7',\n",
    "                output_type=Output.DICT # Get the output as a Python dictionary\n",
    "            )\n",
    "\n",
    "            # --- Process the detailed data to form a single line ---\n",
    "            line_text = []\n",
    "            line_confidence = []\n",
    "            num_words = len(tesseract_data['text'])\n",
    "            \n",
    "            for i in range(num_words):\n",
    "                # Tesseract's confidence is 0-100. -1 means it's not a valid word.\n",
    "                # We only consider words with a confidence > 0.\n",
    "                conf = int(tesseract_data['conf'][i])\n",
    "                if conf > 0:\n",
    "                    word = tesseract_data['text'][i]\n",
    "                    if word.strip(): # Ensure word is not just whitespace\n",
    "                        line_text.append(word)\n",
    "                        line_confidence.append(conf)\n",
    "\n",
    "            # If any valid words were found in the cropped image\n",
    "            if line_text:\n",
    "                # Join words to form the full text line\n",
    "                full_text = \" \".join(line_text)\n",
    "                \n",
    "                # Calculate the average confidence for the line\n",
    "                # And normalize it to a 0.0 to 1.0 scale like PaddleOCR\n",
    "                avg_confidence = (sum(line_confidence) / len(line_confidence)) / 100.0\n",
    "                \n",
    "                # --- Create the entry in the EXACT PaddleOCR format ---\n",
    "                # Format: [box_coordinates, (text, confidence_score)]\n",
    "                paddle_format_line = [box, (full_text, avg_confidence)]\n",
    "                \n",
    "                # Add it to our list of results\n",
    "                reformatted_lines.append(paddle_format_line)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing a box with Tesseract: {e}\")\n",
    "\n",
    "# --- Step 6: Finalize the result structure ---\n",
    "# The final result should be a list containing one list of lines, just like PaddleOCR's output\n",
    "final_results = [reformatted_lines] if reformatted_lines else []\n",
    "\n",
    "# --- Step 7: Print the final combined results ---\n",
    "print(\"\\n--- Final Results (in PaddleOCR format) ---\")\n",
    "print(final_results)\n",
    "\n",
    "# You can now use this `final_results` object just as you would with native PaddleOCR output\n",
    "print(\"\\n--- Printing each line individually ---\")\n",
    "if final_results:\n",
    "    for box, (text, confidence) in final_results[0]:\n",
    "        print(f\"Box: {box}, Text: '{text}', Confidence: {confidence:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3db6c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)\u001b[0m\n",
      "\u001b[32mUsing official model (PP-LCNet_x1_0_doc_ori), the model files will be automatically downloaded and saved in C:\\Users\\User\\.paddlex\\official_models.\u001b[0m\n",
      "\u001b[32mCreating model: ('UVDoc', None)\u001b[0m\n",
      "\u001b[32mUsing official model (UVDoc), the model files will be automatically downloaded and saved in C:\\Users\\User\\.paddlex\\official_models.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-DocLayout-L', None)\u001b[0m\n",
      "\u001b[32mUsing official model (PP-DocLayout-L), the model files will be automatically downloaded and saved in C:\\Users\\User\\.paddlex\\official_models.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to https://paddle-model-ecology.bj.bcebos.com/paddlex/official_inference_model/paddle3.0.0/PP-DocLayout-L_infer.tar ...\n",
      "Downloading PP-DocLayout-L_infer.tar ...\n",
      "[==================================================] 100.00%\n",
      "Extracting PP-DocLayout-L_infer.tar\n",
      "[==================================================] 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_table_cls', None)\u001b[0m\n",
      "\u001b[32mUsing official model (PP-LCNet_x1_0_table_cls), the model files will be automatically downloaded and saved in C:\\Users\\User\\.paddlex\\official_models.\u001b[0m\n",
      "\u001b[32mCreating model: ('SLANeXt_wired', None)\u001b[0m\n",
      "\u001b[33mThe model(SLANeXt_wired) is not supported to run in MKLDNN mode! Using `paddle` instead!\u001b[0m\n",
      "\u001b[32mUsing official model (SLANeXt_wired), the model files will be automatically downloaded and saved in C:\\Users\\User\\.paddlex\\official_models.\u001b[0m\n",
      "\u001b[32mCreating model: ('SLANeXt_wireless', None)\u001b[0m\n",
      "\u001b[33mThe model(SLANeXt_wireless) is not supported to run in MKLDNN mode! Using `paddle` instead!\u001b[0m\n",
      "\u001b[32mUsing official model (SLANeXt_wireless), the model files will be automatically downloaded and saved in C:\\Users\\User\\.paddlex\\official_models.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to https://paddle-model-ecology.bj.bcebos.com/paddlex/official_inference_model/paddle3.0.0/SLANeXt_wireless_infer.tar ...\n",
      "Downloading SLANeXt_wireless_infer.tar ...\n",
      "[==================================================] 100.00%\n",
      "Extracting SLANeXt_wireless_infer.tar\n",
      "[==================================================] 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCreating model: ('RT-DETR-L_wired_table_cell_det', None)\u001b[0m\n",
      "\u001b[32mUsing official model (RT-DETR-L_wired_table_cell_det), the model files will be automatically downloaded and saved in C:\\Users\\User\\.paddlex\\official_models.\u001b[0m\n",
      "\u001b[32mCreating model: ('RT-DETR-L_wireless_table_cell_det', None)\u001b[0m\n",
      "\u001b[32mUsing official model (RT-DETR-L_wireless_table_cell_det), the model files will be automatically downloaded and saved in C:\\Users\\User\\.paddlex\\official_models.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-OCRv4_server_det', None)\u001b[0m\n",
      "\u001b[32mUsing official model (PP-OCRv4_server_det), the model files will be automatically downloaded and saved in C:\\Users\\User\\.paddlex\\official_models.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to https://paddle-model-ecology.bj.bcebos.com/paddlex/official_inference_model/paddle3.0.0/PP-OCRv4_server_det_infer.tar ...\n",
      "Downloading PP-OCRv4_server_det_infer.tar ...\n",
      "[==================================================] 100.00%\n",
      "Extracting PP-OCRv4_server_det_infer.tar\n",
      "[==================================================] 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCreating model: ('PP-OCRv4_server_rec_doc', None)\u001b[0m\n",
      "\u001b[32mUsing official model (PP-OCRv4_server_rec_doc), the model files will be automatically downloaded and saved in C:\\Users\\User\\.paddlex\\official_models.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to https://paddle-model-ecology.bj.bcebos.com/paddlex/official_inference_model/paddle3.0.0/PP-OCRv4_server_rec_doc_infer.tar ...\n",
      "Downloading PP-OCRv4_server_rec_doc_infer.tar ...\n",
      "[==================================================] 100.00%\n",
      "Extracting PP-OCRv4_server_rec_doc_infer.tar\n",
      "[==================================================] 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)\u001b[0m\n",
      "\u001b[32mUsing official model (PP-LCNet_x1_0_doc_ori), the model files will be automatically downloaded and saved in C:\\Users\\User\\.paddlex\\official_models.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m TableRecognitionPipelineV2()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# ocr = TableRecognitionPipelineV2(use_doc_orientation_classify=True) # Specify whether to use the document orientation classification model with use_doc_orientation_classify\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# ocr = TableRecognitionPipelineV2(use_doc_unwarping=True) # Specify whether to use the text image unwarping module with use_doc_unwarping\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# ocr = TableRecognitionPipelineV2(device=\"gpu\") # Specify the device to use GPU for model inference\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m output:\n\u001b[0;32m      9\u001b[0m     res\u001b[38;5;241m.\u001b[39mprint() \u001b[38;5;66;03m## Print the predicted structured output\u001b[39;00m\n",
      "File \u001b[1;32md:\\Download\\Anaconda\\anaconda3\\envs\\paddle_env\\lib\\site-packages\\paddleocr\\_pipelines\\table_recognition_v2.py:141\u001b[0m, in \u001b[0;36mTableRecognitionPipelineV2.predict\u001b[1;34m(self, input, use_doc_orientation_classify, use_doc_unwarping, use_layout_detection, use_ocr_model, overall_ocr_res, layout_det_res, text_det_limit_side_len, text_det_limit_type, text_det_thresh, text_det_box_thresh, text_det_unclip_ratio, text_rec_score_thresh, use_e2e_wired_table_rec_model, use_e2e_wireless_table_rec_model, use_wired_table_cells_trans_to_html, use_wireless_table_cells_trans_to_html, use_table_orientation_classify, use_ocr_results_with_table_cells, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    140\u001b[0m ):\n\u001b[1;32m--> 141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_iter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_doc_orientation_classify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_doc_orientation_classify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_doc_unwarping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_doc_unwarping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_layout_detection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_layout_detection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_ocr_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_ocr_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m            \u001b[49m\u001b[43moverall_ocr_res\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_ocr_res\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlayout_det_res\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayout_det_res\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtext_det_limit_side_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_det_limit_side_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtext_det_limit_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_det_limit_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtext_det_thresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_det_thresh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtext_det_box_thresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_det_box_thresh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtext_det_unclip_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_det_unclip_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtext_rec_score_thresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_rec_score_thresh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_e2e_wired_table_rec_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_e2e_wired_table_rec_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_e2e_wireless_table_rec_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_e2e_wireless_table_rec_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_wired_table_cells_trans_to_html\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_wired_table_cells_trans_to_html\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_wireless_table_cells_trans_to_html\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_wireless_table_cells_trans_to_html\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_table_orientation_classify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_table_orientation_classify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_ocr_results_with_table_cells\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_ocr_results_with_table_cells\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Download\\Anaconda\\anaconda3\\envs\\paddle_env\\lib\\site-packages\\paddlex\\inference\\pipelines\\_parallel.py:129\u001b[0m, in \u001b[0;36mAutoParallelSimpleInferencePipeline.predict\u001b[1;34m(self, input, *args, **kwargs)\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executor\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m    124\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    125\u001b[0m         \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m    126\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    127\u001b[0m     )\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pipeline\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    131\u001b[0m         \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m    132\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    133\u001b[0m     )\n",
      "File \u001b[1;32md:\\Download\\Anaconda\\anaconda3\\envs\\paddle_env\\lib\\site-packages\\paddlex\\inference\\pipelines\\table_recognition\\pipeline_v2.py:1186\u001b[0m, in \u001b[0;36m_TableRecognitionPipelineV2.predict\u001b[1;34m(self, input, use_doc_orientation_classify, use_doc_unwarping, use_layout_detection, use_ocr_model, overall_ocr_res, layout_det_res, text_det_limit_side_len, text_det_limit_type, text_det_thresh, text_det_box_thresh, text_det_unclip_ratio, text_rec_score_thresh, use_e2e_wired_table_rec_model, use_e2e_wireless_table_rec_model, use_wired_table_cells_trans_to_html, use_wireless_table_cells_trans_to_html, use_table_orientation_classify, use_ocr_results_with_table_cells, **kwargs)\u001b[0m\n\u001b[0;32m   1183\u001b[0m doc_preprocessor_image \u001b[38;5;241m=\u001b[39m doc_preprocessor_res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_img\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_ocr_model\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m-> 1186\u001b[0m     overall_ocr_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1187\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeneral_ocr_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1188\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdoc_preprocessor_image\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1189\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtext_det_limit_side_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_det_limit_side_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1190\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtext_det_limit_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_det_limit_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1191\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtext_det_thresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_det_thresh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1192\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtext_det_box_thresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_det_box_thresh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1193\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtext_det_unclip_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_det_unclip_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1194\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtext_rec_score_thresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_rec_score_thresh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1195\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1197\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneral_ocr_pipeline \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m   1198\u001b[0m     (\n\u001b[0;32m   1199\u001b[0m         use_ocr_results_with_table_cells \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1202\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m use_table_orientation_classify \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1203\u001b[0m ):\n\u001b[0;32m   1204\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneral_ocr_config_bak \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Download\\Anaconda\\anaconda3\\envs\\paddle_env\\lib\\site-packages\\paddlex\\inference\\pipelines\\_parallel.py:129\u001b[0m, in \u001b[0;36mAutoParallelSimpleInferencePipeline.predict\u001b[1;34m(self, input, *args, **kwargs)\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executor\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m    124\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    125\u001b[0m         \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m    126\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    127\u001b[0m     )\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pipeline\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    131\u001b[0m         \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m    132\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    133\u001b[0m     )\n",
      "File \u001b[1;32md:\\Download\\Anaconda\\anaconda3\\envs\\paddle_env\\lib\\site-packages\\paddlex\\inference\\pipelines\\ocr\\pipeline.py:432\u001b[0m, in \u001b[0;36m_OCRPipeline.predict\u001b[1;34m(self, input, use_doc_orientation_classify, use_doc_unwarping, use_textline_orientation, text_det_limit_side_len, text_det_limit_type, text_det_max_side_limit, text_det_thresh, text_det_box_thresh, text_det_unclip_ratio, text_rec_score_thresh)\u001b[0m\n\u001b[0;32m    426\u001b[0m sorted_subs_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\n\u001b[0;32m    427\u001b[0m     sub_img_info_list, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msub_img_ratio\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    428\u001b[0m )\n\u001b[0;32m    429\u001b[0m sorted_subs_of_img \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    430\u001b[0m     all_subs_of_img[x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msub_img_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m sorted_subs_info\n\u001b[0;32m    431\u001b[0m ]\n\u001b[1;32m--> 432\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, rec_res \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_rec_model(sorted_subs_of_img)\n\u001b[0;32m    434\u001b[0m ):\n\u001b[0;32m    435\u001b[0m     sub_img_id \u001b[38;5;241m=\u001b[39m sorted_subs_info[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msub_img_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    436\u001b[0m     sub_img_info_list[sub_img_id][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrec_res\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m rec_res\n",
      "File \u001b[1;32md:\\Download\\Anaconda\\anaconda3\\envs\\paddle_env\\lib\\site-packages\\paddlex\\inference\\models\\base\\predictor\\base_predictor.py:211\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, input, batch_size, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m output[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Download\\Anaconda\\anaconda3\\envs\\paddle_env\\lib\\site-packages\\paddlex\\inference\\models\\base\\predictor\\base_predictor.py:267\u001b[0m, in \u001b[0;36mBasePredictor.apply\u001b[1;34m(self, input, **kwargs)\u001b[0m\n\u001b[0;32m    265\u001b[0m     batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_sampler(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_data \u001b[38;5;129;01min\u001b[39;00m batches:\n\u001b[1;32m--> 267\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    268\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m PredictionWrap(prediction, \u001b[38;5;28mlen\u001b[39m(batch_data))\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(batch_data)):\n",
      "File \u001b[1;32md:\\Download\\Anaconda\\anaconda3\\envs\\paddle_env\\lib\\site-packages\\paddlex\\inference\\models\\text_recognition\\predictor.py:63\u001b[0m, in \u001b[0;36mTextRecPredictor.process\u001b[1;34m(self, batch_data)\u001b[0m\n\u001b[0;32m     61\u001b[0m batch_imgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_tfs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReisizeNorm\u001b[39m\u001b[38;5;124m\"\u001b[39m](imgs\u001b[38;5;241m=\u001b[39mbatch_raw_imgs)\n\u001b[0;32m     62\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_tfs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToBatch\u001b[39m\u001b[38;5;124m\"\u001b[39m](imgs\u001b[38;5;241m=\u001b[39mbatch_imgs)\n\u001b[1;32m---> 63\u001b[0m batch_preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m texts, scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_op(batch_preds)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_path\u001b[39m\u001b[38;5;124m\"\u001b[39m: batch_data\u001b[38;5;241m.\u001b[39minput_paths,\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpage_index\u001b[39m\u001b[38;5;124m\"\u001b[39m: batch_data\u001b[38;5;241m.\u001b[39mpage_indexes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrec_score\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores,\n\u001b[0;32m     71\u001b[0m }\n",
      "File \u001b[1;32md:\\Download\\Anaconda\\anaconda3\\envs\\paddle_env\\lib\\site-packages\\paddlex\\inference\\models\\common\\static_infer.py:287\u001b[0m, in \u001b[0;36mPaddleInfer.__call__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    285\u001b[0m x \u001b[38;5;241m=\u001b[39m _sort_inputs(x, names)\n\u001b[0;32m    286\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(np\u001b[38;5;241m.\u001b[39mascontiguousarray, x))\n\u001b[1;32m--> 287\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pred\n",
      "File \u001b[1;32md:\\Download\\Anaconda\\anaconda3\\envs\\paddle_env\\lib\\site-packages\\paddlex\\inference\\models\\common\\static_infer.py:253\u001b[0m, in \u001b[0;36mPaddleInferChainLegacy.__call__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    251\u001b[0m     input_handle\u001b[38;5;241m.\u001b[39mcopy_from_cpu(input_)\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mrun()\n\u001b[1;32m--> 253\u001b[0m outputs \u001b[38;5;241m=\u001b[39m [o\u001b[38;5;241m.\u001b[39mcopy_to_cpu() \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_handles]\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from paddleocr import TableRecognitionPipelineV2\n",
    "\n",
    "pipeline = TableRecognitionPipelineV2()\n",
    "# ocr = TableRecognitionPipelineV2(use_doc_orientation_classify=True) # Specify whether to use the document orientation classification model with use_doc_orientation_classify\n",
    "# ocr = TableRecognitionPipelineV2(use_doc_unwarping=True) # Specify whether to use the text image unwarping module with use_doc_unwarping\n",
    "# ocr = TableRecognitionPipelineV2(device=\"gpu\") # Specify the device to use GPU for model inference\n",
    "output = pipeline.predict(image_path)\n",
    "for res in output:\n",
    "    res.print() ## Print the predicted structured output\n",
    "    res.save_to_img(\"./output/\")\n",
    "    res.save_to_xlsx(\"./output/\")\n",
    "    res.save_to_html(\"./output/\")\n",
    "    res.save_to_json(\"./output/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paddle_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
